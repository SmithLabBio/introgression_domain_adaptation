

## bear1
Confirm that FineTuning and CDAN with lambda 0 produce equivalent results.

## bear2
Compare normalized sfs to non-normalized

## bear3
Domain adaptation with normalized and non-normalized

## bear4
Domain adaptation with normalized and multiple parameters for batch size and learning rates. 

## bear5
No domain adaptation with normalized and multiple parameters for batch size and learning rates. 